{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATE THE INPUT AND OUTPUT URI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_uri = \"mongodb://localhost:27017/Amazon.Reviews\"\n",
    "output_uri = \"mongodb://localhost:27017/Amazon.Reviews\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAKE A SPARK SESSION AND SET MONGODB CONNECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"myProject\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", input_uri) \\\n",
    "    .config(\"spark.mongodb.output.uri\", output_uri) \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.2\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .config(\"spark.executor.memory\", \"10g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Victus15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>myProject</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1e1abc9cb10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READING FROM MONGODB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mongo = spark.read.format(\"mongo\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOW FOR COLLABORATIVE FILTERING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_collab = df_mongo.select('reviewerID', 'asin', 'overall')\n",
    "df_collab.createOrReplaceTempView(\"df_collab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distinct_asin = spark.sql(\"SELECT DISTINCT asin FROM data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distinct_asin.coalesce(1).write.option(\"header\",True) \\\n",
    " .csv(\"asin_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distinct_reviewer = spark.sql(\"SELECT DISTINCT reviewerID FROM data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distinct_reviewer.coalesce(1).write.option(\"header\", True) \\\n",
    "    .csv(\"reviewerID_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_asin = spark.read.csv(\"asin_csv\", header=True)\n",
    "df_asin.createOrReplaceTempView(\"df_asin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_reviewer = spark.read.csv(\"reviewerID_csv\", header=True)\n",
    "df_reviewer.createOrReplaceTempView(\"df_reviewer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_joined.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_joined = spark.sql(\"SELECT ROW_NUMBER() OVER (ORDER BY df_collab.reviewerID) - 1 AS reviewer_index, \\\n",
    "                    ROW_NUMBER() OVER (ORDER BY df_collab.asin) - 1 AS asin_index, \\\n",
    "                    CAST(df_collab.overall AS INTEGER) AS overall \\\n",
    "                    FROM df_collab \\\n",
    "                    INNER JOIN df_asin ON df_collab.asin = df_asin.asin \\\n",
    "                    INNER JOIN df_reviewer ON df_collab.reviewerID = df_reviewer.reviewerID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_joined.write \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"nullValue\", \"\") \\\n",
    "    .option(\"quote\", \"\") \\\n",
    "    .option(\"escape\", \"\") \\\n",
    "    .option(\"mode\", \"overwrite\") \\\n",
    "    .csv(\"All_joined_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_joined_csv = spark.read.csv(\"All_Joined_csv\", header=True)\n",
    "df_joined_csv.createOrReplaceTempView(\"df_joined_csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTERING OUT THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM df_joined_csv where overall > 4\n",
    "\"\"\"\n",
    "\n",
    "filtered_df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the product IDs with the most reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "popular_products = filtered_df.groupBy(\"asin_index\").count().orderBy(col(\"count\").desc()).limit(300).select(\"asin_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "popular_products.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for reviews of popular products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.join(popular_products, on=\"asin_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS MODEL PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.recommendation import ALSModel\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.describe of DataFrame[reviewer_index: int, asin_index: int, overall: int]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = filtered_df.select(col(\"reviewer_index\").cast(\"int\"), col(\"asin_index\").cast(\"int\"), col(\"overall\").cast(\"int\"))\n",
    "filtered_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training, test) = filtered_df.randomSplit([.7, .3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104056989"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE TRAINING DATASET TO USE AFTER MODEL TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training.coalesce(1).write.option(\"header\", True).csv(\"training_csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE TEST DATASET TO USE AFTER MODEL TRAIN AS WELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.coalesce(1).write.option(\"header\", True).csv(\"test_csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ THE TRAINING AND TESTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104056989"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = spark.read.csv(\"training_csv\", header=True)\n",
    "training_df = training_df.select(col(\"reviewer_index\").cast(\"int\"), col(\"asin_index\").cast(\"int\"), col(\"overall\").cast(\"int\"))\n",
    "training_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44592961"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = spark.read.csv(\"test_csv\", header=True)\n",
    "test_df = test_df.select(col(\"reviewer_index\").cast(\"int\"), col(\"asin_index\").cast(\"int\"), col(\"overall\").cast(\"int\")).distinct()\n",
    "test_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "als = ALS(maxIter=2, rank=6, userCol='reviewer_index', itemCol='asin_index', ratingCol='overall', coldStartStrategy='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = als.fit(training_df)SS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE THE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"ALS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD THE SAVED MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ALSModel.load(\"ALS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET RECOMMENDATIONS FROM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|reviewer_index|     recommendations|\n",
      "+--------------+--------------------+\n",
      "|       3221405|[{100006060, 4.96...|\n",
      "|       3627754|[{100015935, 4.96...|\n",
      "|       8511114|[{100011693, 4.96...|\n",
      "|       9737584|[{100013635, 4.96...|\n",
      "|      10246362|[{100016101, 4.96...|\n",
      "|      11582635|[{100002437, 4.96...|\n",
      "|      11930560|[{100011262, 4.96...|\n",
      "|      12191461|[{100013570, 4.96...|\n",
      "|      12296296|[{100016143, 4.96...|\n",
      "|      12614929|[{100021718, 3.96...|\n",
      "+--------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_recs=model.recommendForAllUsers(20).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## EVALUATING MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=0.0021583798928685068\n",
      "+--------------+----------+-------+----------+\n",
      "|reviewer_index|asin_index|overall|prediction|\n",
      "+--------------+----------+-------+----------+\n",
      "|      10760282|   1000127|      4| 3.9974043|\n",
      "|      83476127|   1000146|      5|  4.997922|\n",
      "|     218680506|    100010|      5| 4.9979224|\n",
      "|     219591444|   1000073|      5|  4.997922|\n",
      "|       1614443|  10000600|      5| 4.9979224|\n",
      "|      30351220|  10000021|      5| 4.9979224|\n",
      "|      52928479|  10000528|      5|  4.997922|\n",
      "|      75138366|  10000989|      4| 3.9974043|\n",
      "|      84206832|  10001183|      5| 4.9979224|\n",
      "|      92575672|  10001380|      5|  4.997922|\n",
      "|      98123032|  10001599|      5|  4.997922|\n",
      "|     100427680|  10001677|      5|  4.997922|\n",
      "|     108372703|  10001910|      5|  4.997922|\n",
      "|     123574269|  10001272|      5|  4.997922|\n",
      "|     126250063|  10001331|      4| 3.9974043|\n",
      "|     184678585|  10002084|      5|  4.997922|\n",
      "|     185276685|  10002100|      5| 4.9979215|\n",
      "|     192470325|  10001751|      5|  4.997922|\n",
      "|     215425950|  10000539|      5|  4.997922|\n",
      "|     224482398|  10000761|      5|  4.997922|\n",
      "+--------------+----------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"overall\",predictionCol=\"prediction\")\n",
    "predictions=model.transform(test)\n",
    "rmse=evaluator.evaluate(predictions)\n",
    "print(\"RMSE=\"+str(rmse))\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GET RECOMMENDED BY PRODUCT ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_reviewer = spark.read.csv(\"reviewerID_csv\", header=True)\n",
    "df_reviewer.createOrReplaceTempView(\"df_reviewer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|    reviewerID|\n",
      "+--------------+\n",
      "| AIQDYZVLGWHER|\n",
      "|A3O3B0H45VICX0|\n",
      "|A3EPQDDI5QLVR0|\n",
      "|A3O8XET7PDCNSF|\n",
      "| AECVG05HBE9I0|\n",
      "|A3A5UPM2KP70S2|\n",
      "|A22A0KTRXCN74T|\n",
      "|A13OHG9NAYCRVG|\n",
      "|A170DUCSTHOIGS|\n",
      "|A3R5X3HI509L7X|\n",
      "+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviewer.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|          reviewerID|reviewer_index|\n",
      "+--------------------+--------------+\n",
      "|A0000040I1OM9N4SGBD8|             0|\n",
      "|A0000074RA15UCBH3ON5|             1|\n",
      "|A000013090ZI3HIT9N5V|             2|\n",
      "|A0000148KSJ81F2E3O7V|             3|\n",
      "|A0000188NWOSI5X2PMSN|             4|\n",
      "|A0000196KBA0ICH151EG|             5|\n",
      "|A00003323X6I53YWRGN0|             6|\n",
      "|A000033826RVJH496D4A|             7|\n",
      "|A0000378ZNUHTQUDNNHR|             8|\n",
      "|A0000448ZD4QU0AQCOH8|             9|\n",
      "|A0000618JRL8NVY0J0AN|            10|\n",
      "|A00006301SOXP1JTSSEW|            11|\n",
      "|A00007664HEMMTK5IAWX|            12|\n",
      "|A00007762BKXYRMOCC0A|            13|\n",
      "|A0000862BTSWL73O3J0Y|            14|\n",
      "|A00008882A0PUVHCTDUP|            15|\n",
      "|A0000932YCOC06EWVVQY|            16|\n",
      "|A0000966VPR3PHG0J8GV|            17|\n",
      "|A0000978V0GBY0646VAM|            18|\n",
      "|A00009928J2TXTYX144F|            19|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviewer = spark.sql(\"SELECT reviewerID, ROW_NUMBER() OVER (ORDER BY reviewerID) - 1 AS reviewer_index FROM df_reviewer\")\n",
    "df_reviewer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_reviewer.coalesce(1).write.option(\"header\", True) \\\n",
    "    .csv(\"reviewerID_reviewerIndex_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_reviewer = spark.read.csv(\"reviewerID_reviewerIndex_csv\", header=True)\n",
    "df_reviewer.createOrReplaceTempView(\"df_reviewer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.describe of DataFrame[reviewerID: string, reviewer_index: int]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviewer = df_reviewer.withColumn(\"reviewer_index\", col(\"reviewer_index\").cast(\"integer\"))\n",
    "df_reviewer.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count the number of reviews for each asin\n",
    "df_asin_reviews = df_collab.groupBy(\"asin\").agg(count(\"*\").alias(\"Total_reviews\"))\n",
    "\n",
    "# Join df_asin_reviews with df_asin on the asin column\n",
    "df_asin = df_asin.join(df_asin_reviews, \"asin\")\n",
    "df_asin.createOrReplaceTempView(\"df_asin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviewer_ids = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT df_collab.reviewerID\n",
    "    FROM df_collab\n",
    "    INNER JOIN df_asin ON df_collab.asin = df_asin.asin\n",
    "    WHERE df_collab.overall > 3.5 AND df_asin.Total_reviews >= 1000\n",
    "\"\"\")\n",
    "\n",
    "# Join df_reviewer with reviewer_ids\n",
    "df_reviewer_filtered = df_reviewer.join(reviewer_ids, on=\"reviewerID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[reviewerID: string, reviewer_index: int]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviewer_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_reviewer_filtered.coalesce(1).write.option(\"header\", True) \\\n",
    "    .csv(\"reviewerID_reviewerIndex_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_reviewer = spark.read.csv(\"reviewerID_reviewerIndex_filtered\", header=True)\n",
    "df_reviewer.createOrReplaceTempView(\"df_reviewer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|          reviewerID|reviewer_index|\n",
      "+--------------------+--------------+\n",
      "|A0007154ZQMFVTRTSP3X|           135|\n",
      "|A002556217M3R4LLKZHR|           436|\n",
      "|A0031944XK4KVC58YJ6I|           542|\n",
      "| A0044154XURSDJT4N4I|           755|\n",
      "|A0072319W2B8TUXQHHD1|          1210|\n",
      "|A0074159BRRBJRK1EAOY|          1237|\n",
      "|A0089557DXY1OSDNNIEC|          1492|\n",
      "|A0092907G6YM6TJ2KMKK|          1544|\n",
      "|A009516920GSIZCMS1JK|          1578|\n",
      "|A0098677SNWYKXZKBJB0|          1639|\n",
      "+--------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviewer.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
